%% This is emulateapj reformatting of the AASTEX sample document
%%
\documentclass[iop]{emulateapj}

\newcommand{\vdag}{(v)^\dagger}
\newcommand{\myemail}{jselsing@dark-cosmology.dk}

%% You can insert a short comment on the title page using the command below.

\slugcomment{Draft version, July 31, 2014}

%% If you wish, you may supply running head information, although
%% this information may be modified by the editorial offices.
%% The left head contains a list of authors,
%% usually a maximum of three (otherwise use et al.).  The right
%% head is a modified title of up to roughly 44 characters.
%% Running heads will not print in the manuscript style.

\shorttitle{Host-Free Quasar Composite}
\shortauthors{Selsing et al.}

%% This is the end of the preamble.  Indicate the beginning of the
%% paper itself with \begin{document}.

\begin{document}

%% LaTeX will automatically break titles if they run longer than
%% one line. However, you may use \\ to force a line break if
%% you desire.

\title{Host-Free Quasar Composite Spectrum}

%% Use \author, \affil, and the \and command to format
%% author and affiliation information.
%% Note that \email has replaced the old \authoremail command
%% from AASTeX v4.0. You can use \email to mark an email address
%% anywhere in the paper, not just in the front matter.
%% As in the title, use \\ to force line breaks.

\author{J. Selsing\altaffilmark{1}, J. P. U. Fynbo\altaffilmark{1}, L. Christensen\altaffilmark{1}, J. K. Kroager\altaffilmark{1}}
\email{jselsing@dark-comoslogy.dk}


%% Notice that each of these authors has alternate affiliations, which
%% are identified by the \altaffilmark after each name.  Specify alternate
%% affiliation information with \altaffiltext, with one command per each
%% affiliation.

\altaffiltext{1}{Dark Cosmology Centre, Niels Bohr Institute, University of Copenhagen, Juliane Maries Vej 30, 2100 Copenhagen, Denmark}


%% Mark off your abstract in the ``abstract'' environment. In the manuscript
%% style, abstract will output a Received/Accepted line after the
%% title and affiliation information. No date will appear since the author
%% does not have this information. The dates will be filled in by the
%% editorial office after submission.

\begin{abstract}
QSO templates are important both for QSO physics and for projects using QSOs as probes. However, the current most widely used QSO template, namely the SDSS composite QSO spectrum of Vanden Berk et al. (2001) suffers from significant host galaxy contamination redwards of 5000\AA in the restframe. At these wavelenghts the SDSS template is based on intrinsically faint, low-redshift QSOs. We here propose to build a composite QSO spectrum for bright blue QSOs without this problem using X-shooter GTO time. With X-shooter we can target bright SDSS QSOs in the redshift range $1 < z < 2.3$ and hence build a composite spectrum covering the full range from Ly$\alpha$ to 8500\AA in the restframe without significant host galaxy contamination.

\end{abstract}

%% Keywords should appear after the \end{abstract} command. The uncommented
%% example has been keyed in ApJ style. See the instructions to authors
%% for the journal to which you are submitting your paper to determine
%% what keyword punctuation is appropriate.

%% Authors who wish to have the most important objects in their paper
%% linked in the electronic edition to a data center may do so in the
%% subject header.  Objects should be in the appropriate "individual"
%% headers (e.g. quasars: individual, stars: individual, etc.) with the
%% additional provision that the total number of headers, including each
%% individual object, not exceed six.  The \objectname{} macro, and its
%% alias \object{}, is used to mark each object.  The macro takes the object
%% name as its primary argument.  This name will appear in the paper
%% and serve as the link's anchor in the electronic edition if the name
%% is recognized by the data centers.  The macro also takes an optional
%% argument in parentheses in cases where the data center identification
%% differs from what is to be printed in the paper.

\keywords{quasars: general --- quasars: composite spectrum --- quasars: host galaxy}


\section{Introduction}

Template spectra are useful for a wide range of purposes, e.g., the detection of features that are too weak to be detected in individual spectra, identification of objects that differ from the mean, etc. Examples of such composite spectra include template spectra of various classes of galaxies (Shapley et al. 2003, ApJ, 588, 65S; Dobos et al. 2012, MNRAS, 420, 1217), QSOs (Cristiani \& Voi 1990, A\&A, 227, 385C; Boyle 1990, MNRAS, 243, 231; Francis et al. 1991, ApJ, 373, 465; Brotherton et al. 2000, ApJ, 546, 775; Vanden Berk et al. 2001, AJ, 122, 549; Telfer et al. 2002, ApJ, 565, 773) and GRB afterglows (Christensen et al. 2011, ApJ, 727, 73). In particular, QSO composite spectra have been studied and discussed intensively since the first papers in the early 1990ies.

\newpage


\section{Problems with the current most used template}
The currently most widely used QSO template is the SDSS template of Vanden Berk et al. (2001, cited more than 600 times in ADS). As described very clearly in that paper the SDSS composite spectrum shows a strong change in the spectral slope around 5000  ÌŠA. This is mainly attributed to contaminating light from the underlying host galaxy. Other effects also contribute, e.g. emission from a hot dust component, but the dominating factor is likely the host contamination. Our main motivation for building a QSO template without this problem is the following: we have initiated a search for dust-reddened QSOs using near-IR (NIR) selection of QSOs. In stripe 82 we have studied about 50 such candidate QSOs using the NTT in P88 (088.A-0098). Whereas we searched for QSOs reddened by foreground absorber galaxies most systems we observe turn out to be QSOs reddened by dust in their host galaxies. The optical spectra can be well matched by the SDSS template spectrum reddened by SMC-like extinction, but the NIR (restframe optical) photometry from UKIDSS cannot be fitted. The problem is illustrated in Fig. 1 where we attempt to model the EFOSC2 spectrum of a dust-reddened QSO at z = 1.16 here observed in our survey. As seen, the SDSS spectrum and photometry can be well matched with the Vanden Berk template, but the photometry from UKIDSS is much too blue for even the unreddened template. This is not a unique case, but a problem that is seen for all the dust reddened QSOs found in our search.
In the SDSS composite the QSOs contribution to the spectrum at $ > 5000$\AA have to be at fairly low redshifts ($z \lesssim  0.5$). These QSOs have absolute magnitudes that are $3-4$ magnitudes fainter than bright $z > 1.5$ QSOs (see Fig. 2 taken from in Vanden Berk et al. 2001). They are also likely to have the brightest restframe optical host galaxies and hence host contamination is not surprising. Hence, by selecting intrinsically much brighter QSOs at higher redshifts we should be able to avoid the problem with host contamination.




\section{Sample description}
In order to build a QSO spectrum with no significant host galaxy contamination we select very bright ($r \lesssim 17$) SDSS QSOs at redshifts $1 < z < 2.1$ for which host galaxy contamination should be insignificant and where we can use the redshift distribution to cover the regions of strong telluric absorption. Previous QSO templates in the literature have been based on hundreds of spectra, but this is neither possible nor necessary for us. We are mainly interested in tracing the shape of the continuum with negligible host contamination and for that a smaller sample will suffice. We have consequently selected the 7 brightest SDSS QSOs at $1 < z < 2.1$ and at declinations $\lesssim +15^\circ$ that are observable in a single visitor run and that have SDSS spectra without signs of BAL activity or other strong associated absorption systems. With this sample all restframe wavelengths from Ly$\alpha$ to 8500\AA will be covered by at least ? spectra where we have corrected spectra for telluric absorption, which will give us a handle on the variance also. For all of the spectra we cover the region of [OII],3727 and [OIII],5007 , which is useful for determination of precise systemic redshifts.

Spectroscopic observation of the targets have been carried out using X-shooter, the single-object cross-dispersion echelle spectrograph installed in UT2 at the Very Large Telescope (VLT). The observations were carried out March, 2013 and for each object they consists of 4 exposures in nodding mode in the sequence ABBA with a total integration time of 1800s per object, simultaneous in the UVB($3000 - 5500$\AA), VIS($5500 - 10150$\AA)  and NIR($10150 - 24800$\AA) arms. The nominal resolving power $R = \lambda / \Delta \lambda$ for our observations is 4350 in the UVB-arm for a slit width of 1".0, 7450 and 5300 in the VIS- and NIR arms, respectively for a slit width of 0".9. For one observation, slit widths of 1".3 for UVB and 1".2 for VIS and NIR have been used thus lovering the nominal resolution. The seeings were photometric, reaching 0".66 as determined from the width of the trace at 7825\AA and therefore the delivered effective resolution will be higher than tabulated. We determine the instrument spectral seeing FWHM using MOLECFIT where a model atmosphere is convolved with a Gaussian kernel and a fit against the telluric absorption bands in the visual arm is done for the width of the Gaussian kernel. The size of the kernel used increases linearly with wave wavelength to keep the resolution constant as is indeed the case for X-shooter and the FWHM values are related to the central wavelength, which in the case for the visual arm is at 7825\AA. 

\begin{figure}
\epsscale{1.0}
\plotone{Seeing.eps}
\caption{Measured spatial seeing from width of trace against effective spectral resolution. All the observations are seeing-limited and thus the effective resolution will be higher than tabulated. (see text)\label{seeing}}
\end{figure}

As can be seen from Figure \ref{seeing} our observations are done at resolutions between 11000 and 14500 in the visual arm, all of them significantly higher than the nominal values. If we assume that the ratio of measured spatial seeing FWHM to spectral seeing FWHM remains constant we get the resolution in UVB and VIS from the width of the traces in the respective arms taking into account the different pixel-scale in the NIR arm.\\ \\
Insert new resolutions
\\

The resolution is important for the construction of the composite since we need to rebin the spectra to a common dispersion at a common redshift keeping the sampling of the pixels at the optimal Nyquist sampling (2 pixels per FWHM)

The data were reduced using the ESO/X-shooter pipeline v2.5.2 (Modigliano), where we have rectified all spectra on a grid with 0.2 \AA/pixel thus slightly oversampling even the highest-resolution spectra without introducing too much correlation between adjacent pixels in the rectification. The spectra were extracted in the standard way and were flux calibrated using photometric standards. \\ \\

Calibrate to SDSS \\


Telluric observations of hot dwarfs were taken close in time to allow for an accurate telluric correction which depends heavily on the atmospheric conditions at the time of observation.



\newcommand\sk[2]{Sk\,{$-#1{^\circ}#2$}}
\newcommand\tnc{\,\tablenotemark{c}}
\newcommand\tnd{\,\tablenotemark{d}}


\begin{deluxetable}{lllll}
\tabletypesize{\footnotesize}
\tablecolumns{4} 
\tablewidth{0pt} 
\tablecaption{Quasars in the composite}
\tablehead{\colhead{Quasar name}                                 			   &
           \colhead{$\alpha$(J2000)}                           				    	  &
           \colhead{$\delta$(J2000)}                   &
           \colhead{$r$}                   &
%           \mu
           \colhead{$z_{SDSS}$\,\tablenotemark{a}}                                   }
\startdata
%SDSS0043+0114  & 00:43:15.08 & $+$01:14:45.56 & 17.58 & 1.564      \\
%SDSS0155-1023  & 01:55:04.73 & $-$10:23:28.38 & 17.35 & 1.549        \\
%SDSS0209-0947  & 02:09:51.08 & $-$09:47:27.34 & 17.90 & 1.568       \\
%SDSS0303+0027  & 03:03:42.78 & $+$00:27:00.50 & 17.84 & 1.647       \\
%SDSS0323-0029  & 03:23:49.53 & $-$00:29:49.88 & 17.81 & 1.628      \\
SDSS0820+1306  & 08 20 45.39 & $+$13 06 18.99 & 15.91 & 1.126        \\
%SDSS0842+0151  & 08:42:40.63 & $+$01:51:34.14 & 17.62 & 1.485       \\
%SDSS1002+0331  & 10:02:48.15 & $+$03:31:55.98 & 17.74 & 1.482      \\
SDSS1150-0023  & 11 50 43.88 & $-$00 23 54.07 & 17.00 & 1.980         \\
%SDSS1158-0322   & 11:58:41.37 & $-$03:22:39.93 & 17.56 & 1.576        \\
SDSS1219-0100  & 12 19 40.37& $-$01 00 07.49& 16.82 & 1.577           \\
SDSS1236-0331  & 12 36 02.34 & $-$03 31 29.94 & 16.91 & 1.824          \\
SDSS1354-0013  & 13 54 25.24 & $-$00 13 58.06 & 16.68 & 1.512          \\
SDSS1431+0535  & 14 31 48.09 & $+$05 35 58.10 & 16.74 & 2.096      \\
SDSS1437-0147  & 14 37 48.29 & $-$01 47 10.79 & 15.44 & 1.309          \\

\enddata

\tablenotetext{a}{Taken from SDSS }
  

\end{deluxetable}



\subsection{Telluric Correction}
All ground based instruments suffer from atmospheric absorption. This is especially true in the Visual (VIS) and Near-Infra-Red (NIR) arm of X-shooter where there are regions of severe telluric absorption from water vapor.  Because of our limited sample-size, it is desirable to avoid simply masking out regions of atmospheric absorption, but rather correct for them and therefore we investigate which of several methods of telluric correction that maximizes our S/N without introducing artifacts. (molecfit, xsh-library method, my method). To correct for this absorption you need an exact measure of the transmission of the atmosphere at the time of your observation. The amount of absorption is heavily dependent on the exact conditions through the atmosphere and these changes on very short timescales. This transmission has been modeled as a function of airmass and precipitable water vapor and synthetic transmission-spectra are accessible via the web application SKYCALC developed by ESO.  Another take, MOLECFIT, at determining the transmission of the atmosphere is by directly fitting the telluric aborption region with a radiative transfer code thus simultaneously also fitting for the molecular content of the atmosphere. Here the initial guess on the atmospheric conditions are taken from the header of the observation. For a given atmospheric model the molecular content can then be varied and convolved with a instrument-specific kernel to obtain the correct instrumental profile. \\

\begin{figure}
\epsscale{1.25}
\plotone{tell_corr_QC.eps}
\caption{VIS arm of the telluric standard Hip040217 in black. Overplotted in red is the best fit template stellar model atmosphere combination. As can be seen, at 8400\r{A}  there are local deviations in the order 5 \%.\label{tellqc}}
\end{figure}

In the method employed by the Xshooter-Spectral-Library (XSL), Chen2014b, a library of telluric transmission are creating from observations of featureless telluric standard stars. For each observation an optimal template is found from the POLLUX library of model stellar atmospheres, excluding the regions of telluric absorption in the fit, thus tracing the intrinsic stellar spectral shape. This optimal template is then divided by the object spectrum to create a transmission spectrum. These transmission-curves are then compiled in a library of corrections. When the telluric correction are to be made on the object the regions of telluric regions are fit for the template to find the optimal transmission, regardless of the temporal similarity of the transmission-curve and the object spectrum. The method we use is closely related to the one employed by XSL. We have observations of telluric standard stars close in time to the science observation. To get the transmission-curve from the telluric observations we find the optimal template among the model atmospheres of GÃ¶ttingen Spectral Library Husser2013a. Here they have used the PHOENIX model stellar atmosphere code to create a grid of synthetic spectra in terms of effective temperature, metallicity and alpha element enhancement. To find the optimal template we simultaneusly fit for the instrumental profile broadening, velocity shift and optimal template using the penalized-pixel fitting software pPXF Cappellari2014 to find the linear combination of spectra and spectral broadening that minimizes $\chi ^2$ between our object spectrum and the found template . For the fitting we exclude all regions of strong telluric absorption since we only want to trace the continuum. This way of doing the optimal template fit risks finding an unphysical model since we have not constrained the allowed model stellar atmospheres. The reason for doing this is that we want trace the signal as well as possible regardless of the actual shape. An alternative would be non-parametric regression, but here we would loose potential stellar features in the masked regions. !!!Investige reason for uncorrectly traced object(8400\r{A}). As can be seen in Fig. \ref{tellqc}, the telluric standard spectrum is traced relatively well. The regions where the object is not found accurately will produce an erroneous transmission correction and introduce an error in the resulting composite spectrum. We review the consequences of this later. 




\section{Composite Construction}

\subsection{Determine redshift}
Getting the systemic redshift of quasars from emission lines is complicated by the complex physical structure in which they emitted. For the bright blue quasars selected for our composite many of the prominent high-ionization lines visible will arise in hot clouds with large peculiar velocities and will therefore be affected by systematic line-shifts (reference). To get a redshift closer to the systemic we choose [OIII] $\lambda$5007,  arising in the narrow-line region and therefore less affected by systematic offsets, (reference) to fit for the redshift. [OIII] is situated on a broad Fe-complex and slightly blended with [OIII] $\lambda$4959 and H$\beta$, with H$\beta$ both containing broad and narrow components. To get an accurate estimate of the redshift we mark both sides of the line belonging to [OIII] $\lambda$5007 where it starts to become blended, do a low order polynomial fit to the edges and subtract this pseudo-continuum. We define a Gaussian in terms of the rest wavelenght of [OIII] and leave the redshift as a free parameter and then fit to the line where a weighted minimization of the residuals is done using least squares and the confidence intervals on the best-fit parameters is determined by resampling from a multivariate Gaussian with best-fit values as the mean and a covariance matrix which is the estimated Hessian at the minimum. The weights used are the inverse variance, $\frac{1}{\sigma^2}$, where $\sigma$ is the statistical error of the spectrum. The 1$\sigma$ confidence intervals on the fit parameters are set by the 16th and 84th percentile of the resampling realizations. Least squares minimization do not guarantee to find the global minimum of the residuals, but we check visually that the fit is satisfactory. [OIII] $\lambda$5007 is visible in all of our spectra so additional refinement is not needed. As a starting guess for the redshift we use redshifts queried from SDSS. For all of our spectra we find slight corrections to the redshift.

\begin{figure}
\epsscale{1.25}
\plotone{LineFit.pdf}
\caption{Gaussian fit of [OIII] $\lambda$5007. The red solid line is the linear-least-squared best fit with 1$\sigma$ confidence interval. Green dashed lines indicate the position of neighboring lines at the redshift of [OIII]. It can be seen that H$\beta$ is red-shifted as compared with the redshift of [OIII], indicative of large peculiar velocities.\label{linefit}}
\end{figure}

\subsection{Rebin}
Before we can combine the spectra we need to move then to their local frame and because of the varying redshifts of the objects, the spectra will have their arms overlap at different locations. X-shooter, being a cross-dispersion echelle spectrograph, will have a non-linear dispersion solution and order to conserve the most information without oversampling we need to choose a representative bin size on which to interpolate our spectra to. The largest sampling in the NIR arm is $0.6$\r{A}/pix and for an average redshift of $z_{avg} = 1.6$ gives us the conservative bin size of $0.4$\r{A}/pix at the rest-frame. Since our spectra have significantly better resolution than the nominal values and the UVB and VIS arms have a sampling of $0.2$\r{A}/pix we will be throwing away spectral information to make sure that we are not oversampling. We create a wavelength grid from 1000-11665\r{A} in steps of 0.2\r{A} giving $\sim$ 55000 spectral elements on which we linearly interpolate our shifted spectra. Since the constituent spectra have higher sampling than the target grid (elaborate here?)

\subsection{Normalisation and combination}
In order to combine the spectra in a meaningful way, we need to put them on equal grounds as not to favor one spectrum over the other and biasing our final spectrum towards a certain kind of shape. Depending on the type of features we are interested in and on the combination method employed, there are different ways to achieve this normalization. Because the spectra have different absolute flux-scales, a popular way to normalize is to order the spectra in increasing wavelength, start with the lowest redshift, scale the entire spectrum by the median value of the flux and in the overlapping region with the next spectrum, scale with the median and then take the average, combining the spectra consecutively, always scaling to overlapping region. The region chosen will affect how the final spectrum will look. In principle that standard deviation of the composite should reflect the intrinsic variability of constituent spectra, but the region to which we scale will affect this standard deviation. To make the variance reflect the viability the most the spectra have been scaled in the region with the least variability, which is just redwards of H$_\alpha$ in the region 7000- 7500 \r{A}. Each spectrum have been divided by the median flux in this region, thus the normalization is independent and the order in which the combination is done does not matter. (references: Eces paper, Richards 2006). (Also need to be expanded). We also correct for Galactic extinction using extinction values queried from SDSS using the parametrisation 

Before any combination is done, all spectra have been run through a filter, where if the change from pixel to pixel is greater than 20 \%, the pixel is flagged and excluded from the combination. This is to exclude bad pixels and pixels affected too seriously by telluric absorption correction. We have investigated whether this exclusion changes the shape of the combined continuum and no effect was visible. This way of flagging noisy pixels, ensures that we retain as much signal as possible without introducing very noisy isolated pixels. 

Choosing the right combination method is tricky business and each method has it's pros and cons. The first assumption is that at each pixel, that constituent spectra have a Gaussian distribution around a sample mean and that this mean reflects the expectation value of the sample. Since we have a relatively small sample, even investigating whether we have a Gaussian distribution is tricky. To make a crude estimate of normality, we take one pixel along the composite and plot a histogram of the individual constituent pixels. To this distribution we overplot the Gaussian that would arise, if the data was normally distributed. We do this for 50 pixels, where we normalise the pixel values by the median value of the pixels. Since we one have 7 pixels, determining whether the constituent spectra are normally distributed, is a guess at best. We show a crude plot in Fig. \ref{fig4}, where it is not immediately evident if we are normal. We also run a normality test where we take 1000 pixels from the central part of the spectrum. On each pixel we run a normality test which gives us a 2-sided chi squared probability for the hypothesis test, under the null hypothesis that the sample comes from a normal distribution. With an average of $p = 0.31$ we can a least not reject, that we are sampling from a normal distribution. With a larger sample, this test could significantly be improved, especially the test for normality of the kurtosis, which is unstable below 20 elements in the test. 

 \begin{figure}
 \epsscale{1.25}
 \plotone{normality.pdf}
 \caption{Test for normality in individual pixels.\label{normality}}
 \end{figure}

In the case for uncorrelated pixels the minimal variance point estimation for the sample mean is the inverse variance weighted mean, given again that the pixels can be treated as stochastic variables that follow a normal distribution $\mathcal{N}(\mu, \sigma_i^2)$ with mean $\mu$ and variance $\sigma_i^2$. The inverse variance weighted mean is calculated as:

\begin{equation}
\
\bar{f_{\lambda}} = \frac{ \sum_{i=1}^n \left( f_{\lambda, i} \sigma_{\lambda, i}^{-2} \right)}{\sum_{i=1}^n \sigma_{\lambda, i}^{-2}}
\end{equation}

 with the variance of the weighted mean given as: 
 
 \begin{equation}
 \sigma_{\bar{f_{\lambda}}}^2 = \frac{ 1 }{\sum_{i=1}^n \sigma_{\lambda, i}^{-2}}.
\end{equation}

The echellity of x-shooter makes it necessary to resample the image on a rectified image and this process introduces correlations between adjacent pixels. Since we have again rebinned the pixels to the common pixel scale additional correlation between adjacent pixels will be introduced both the the flux spectrum and in the error spectrum, meaning that we will be underestimating the errors in the resulting composite spectrum where the statistical noise will be hiding in pixel-top-pixel variations. On top of that, since our objects are fairly bright, the Poisson noise in our spectra will be non-negligible and thus we are incorporating the pixels values themselves intro their weight which often leads to biasing the result towards spectra of lower signal-to-noise. We check whether the combination method employed affects the qualitative features in our spectrum in the next section.

Bootstrapping to estimate true population CI? - Not viable for weighted average, but ok for mean and median. 




\section{Results}

We show the weighted mean composite in Fig. \ref{composite}. Characteristic features of quasars are readily visible, where plotted on log-log scale the continuum shows the broken power-law shape with the break around 5000 \r{A} a is usually detected. We see several prominent emission lines across the entire spectral range which includes both very broad high-ionization lines and narrower lower-ionization lines as is very typical for quasar spectra.  



 We have overplotted, in the blue, the weighted mean composte from Vanden Berk and as can be seen there is excellent agreement between the two composites from Ly$\alpha$ at 1216 \r{A} up to H$\gamma$ at 4340 \r{A}. As is commonly seen in quasar spectra there is a break in the spectrum at around 5000 \r{A}, where there is a significant discrepancy between the slope of the two composites, attributed to the relative contribution of host starlight, where the composite by Vanden Berk consists of low-redshift, intrinsically fainter objects with a higher fraction of host contamination. Does it make sense to fit a powerlaw to this? To quantify we fit power laws to the same regions as used by Vanden Berk and find .. ... .... . Expand this section a lot. Our data is well modelled by a single power law from 5000 \r{A} to 11000 \r{A}. 
 
 This should be described in greater detail.

\subsection{Consequence of combination/sampling/telluric/ methods}
To test effect of the $\sim$ 10 \% variation of the accuracy of our flux-calibration compared with the corresponding object spectra obtained with SDSS, we generate the composite from the SDSS spectra. We see a very close agreement between the two composites and estimate that the error in the flux-calibration is within 10\%.
% Do this

To test the magnitude of the noise introduced by the telluric correction employed we do the combinations where instead of correcting for the tellurics we exlclude region of telluric absorbtion. The effect on the composite  
%Do this

To test the effect of the sampling step size chosen we do all the combinations with varying sampling step and we find no difference in the qualitative results. 
%Do this



 To ensure that we are not biasing the composite towards the spectra with the highest signal-to-noise we compare the error-weighted mean composite with the composite generated from the mean.
 %Do this
 
  
In general the mean spectra will not result in an estimated slope with the mean spectral index $\langle a_\lambda\rangle$. To obtain the mean slope we take the Geometric mean which \textit{does} result in the resulting slope equalling the mean slope. 
%Do this. Maybe push further up.





\subsection{The case of Q0918+1636}
To check whether we have addressed the problem
 with the near-infrared excess, we start checking if we can adequately fit for the amount of intrinsic visual extinction in one of heavily extincted quasars, where we know the existing composite to be insufficient. We use the gordon-parametrisation with smc-like dust and fit for $A_V$
 
 \subsection{The case of Q2222-0946}
Here we redo the analysis of the previous subsection on the object Q2222-0946.

 

 \begin{figure*}
  \epsscale{1.25}
 \plotone{Composite.pdf}
 \caption{Composite spectrum.\label{composite}}
 \end{figure*}

 \begin{figure}
 \epsscale{1.25}
 \plotone{signal_to_noise.pdf}
 \caption{Signal-to-noise for the composite.\label{sn}}
 \end{figure}

 \begin{figure}
 \epsscale{1.25}
 \plotone{number_spec.pdf}
 \caption{Number of spectra contributing to the composite.\label{number}}
 \end{figure}

 \begin{figure}
 \epsscale{1.25}
 \plotone{std.pdf}
 \caption{Variation in spectra.\label{number}}
 \end{figure}


\section{Discussion}
Something extremely profound.



\subsection{Comparison to existing composites}
Continuum shape. Emission and absorption lines. Comparison with existing composites ( Vanden Berk, Glickman). Above 10000 \r{A} only 1 spectrum contribute to compostie and is therefore not well constrained. 


\subsection{Consequences of application to Q0918+1636 and Q2222-0946}
We see that we adequately can match the infrared photometry by deredding the composite we have constructed


\subsection{Discussion of systematic}

Selection effects always play a role in the result. We now discuss the possible effects selection has on our results. We have selected quasar at $r \lesssim 17.5$ and at z = 1-2. 

\subsection{Discussion of systematic effects from the choice of targets}




\section{Conclusion}
We have reinvented the wheel.

We have generated a quasar composite from 1000 \r{A} to 11000 \r{A} based on X-shooter observations of bright blue quasars at z = 1 - 2. We have confirmed that there is significant host-contamination in the widely employed Vanden Berk composite, and showed the difference this makes for the matching of photometry of red quasars


%\bibliographystyle{plain}
%\bibliography{/Users/jselsing/Work/Papers/bibtex/Husser2013a.bib}
%\bibliography{/Users/jselsing/Work/Papers/bibtex/Cappellari2014.bib}
%\bibliography{/Users/jselsing/Work/Papers/bibtex/Chen2014b.bib}

%% The following command ends your manuscript. LaTeX will ignore any text
%% that appears after it.

\end{document}

%%
%% End of file `sample.tex'.
